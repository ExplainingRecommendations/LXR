{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import sparse\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1274857-c2d4-414c-bf1d-64f29473833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP_DIR = \"Data_preprocessing\"\n",
    "export_dir = Path(os.getcwd())\n",
    "files_path = Path(export_dir.parent, DP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8241ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mixed = pd.read_csv(Path(files_path,'train_data.csv'))\n",
    "test_data = pd.read_csv(Path(files_path,'test_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 19155\n",
    "num_items = 9639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877aa10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_array = torch.eye(num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = train_data_mixed.iloc[:,:-3].to_numpy()\n",
    "test_array = test_data.iloc[:,:-2].to_numpy()\n",
    "test_y_pos = test_data['y_positive'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array_without_item = test_array.copy()\n",
    "for i in range(len(test_array)):\n",
    "    test_array_without_item[i][test_y_pos[i]] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef94c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Base model class\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "    def forward(self, *input):\n",
    "        pass\n",
    "\n",
    "    def train_one_epoch(self, *input):\n",
    "        pass\n",
    "\n",
    "    def predict(self, eval_users, eval_pos, test_batch_size):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbae397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VAE model\n",
    "\n",
    "class MultVAE(BaseModel):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder with Multninomial Likelihood model class\n",
    "    \"\"\"\n",
    "    def __init__(self, model_conf, num_users, num_items, device):\n",
    "        \"\"\"\n",
    "        :param model_conf: model configuration\n",
    "        :param num_users: number of users\n",
    "        :param num_items: number of items\n",
    "        :param device: choice of device\n",
    "        \"\"\"\n",
    "        super(MultVAE, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "\n",
    "        if isinstance(model_conf['enc_dims'], str):\n",
    "            model_conf['enc_dims'] = eval(model_conf['enc_dims'])\n",
    "        self.enc_dims = [self.num_items] + model_conf['enc_dims']\n",
    "        self.dec_dims = self.enc_dims[::-1]\n",
    "        self.dims = self.enc_dims + self.dec_dims[1:]\n",
    "\n",
    "        self.total_anneal_steps = model_conf['total_anneal_steps']\n",
    "        self.anneal_cap = model_conf['anneal_cap']\n",
    "\n",
    "        self.dropout = model_conf['dropout']\n",
    "        # self.reg = model_conf.reg\n",
    "\n",
    "        self.eps = 1e-6\n",
    "        self.anneal = 0.\n",
    "        self.update_count = 0\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = nn.ModuleList()\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.enc_dims[:-1], self.enc_dims[1:])):\n",
    "            if i == len(self.enc_dims[:-1]) - 1:\n",
    "                d_out *= 2\n",
    "            self.encoder.append(nn.Linear(d_in, d_out))\n",
    "            if i != len(self.enc_dims[:-1]) - 1:\n",
    "                self.encoder.append(nn.ReLU())\n",
    "\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dec_dims[:-1], self.dec_dims[1:])):\n",
    "            self.decoder.append(nn.Linear(d_in, d_out))\n",
    "            if i != len(self.dec_dims[:-1]) - 1:\n",
    "                self.decoder.append(nn.ReLU())\n",
    "                \n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, rating_matrix):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        :param rating_matrix: rating matrix\n",
    "        \"\"\"\n",
    "        # encoder\n",
    "        if len(rating_matrix.shape) == 1:\n",
    "            rating_matrix = torch.unsqueeze(rating_matrix, 0)\n",
    "        h = F.dropout(F.normalize(rating_matrix, dim=-1), p=self.dropout, training=self.training)\n",
    "        for layer in self.encoder:\n",
    "            h = layer(h)\n",
    "\n",
    "        # sample\n",
    "        mu_q = h[:, :self.enc_dims[-1]]\n",
    "        logvar_q = h[:, self.enc_dims[-1]:]  # log sigmod^2  batch x 200\n",
    "        std_q = torch.exp(0.5 * logvar_q)  # sigmod batch x 200\n",
    "        \n",
    "        epsilon = torch.zeros_like(std_q).normal_(mean=0, std=0.01)\n",
    "        sampled_z = mu_q + self.training * epsilon * std_q\n",
    "\n",
    "        output = sampled_z\n",
    "        for layer in self.decoder:\n",
    "            output = layer(output)\n",
    "\n",
    "        if self.training:\n",
    "            kl_loss = ((0.5 * (-logvar_q + torch.exp(logvar_q) + torch.pow(mu_q, 2) - 1)).sum(1)).mean()\n",
    "            return output, kl_loss\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def train_one_epoch(self, dataset, optimizer, batch_size):\n",
    "        \"\"\"\n",
    "        Train model for one epoch\n",
    "        :param dataset: given data\n",
    "        :param optimizer: choice of optimizer\n",
    "        :param batch_size: batch size\n",
    "        :param verbose: verbose\n",
    "        :return: model loss\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "\n",
    "        # user, item, rating pairs\n",
    "        train_matrix = dataset\n",
    "\n",
    "        num_training = train_matrix.shape[0]\n",
    "        num_batches = int(np.ceil(num_training / batch_size))\n",
    "        perm = np.random.permutation(num_training)\n",
    "\n",
    "        loss = 0.0\n",
    "        for b in range(num_batches):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if (b + 1) * batch_size >= num_training:\n",
    "                batch_idx = perm[b * batch_size:]\n",
    "            else:\n",
    "                batch_idx = perm[b * batch_size: (b + 1) * batch_size]\n",
    "            batch_matrix = torch.FloatTensor(train_matrix[batch_idx]).to(self.device)\n",
    "\n",
    "            if self.total_anneal_steps > 0:\n",
    "                self.anneal = min(self.anneal_cap, 1. * self.update_count / self.total_anneal_steps)\n",
    "            else:\n",
    "                self.anneal = self.anneal_cap\n",
    "\n",
    "            pred_matrix, kl_loss = self.forward(batch_matrix)\n",
    "\n",
    "            # cross_entropy\n",
    "            ce_loss = -(F.log_softmax(pred_matrix, 1) * batch_matrix).sum(1).mean()\n",
    "\n",
    "            batch_loss = ce_loss + kl_loss * self.anneal\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            self.update_count += 1\n",
    "\n",
    "            loss += batch_loss\n",
    "            if b % 200 == 0:\n",
    "                print('(%3d / %3d) loss = %.4f' % (b, num_batches, batch_loss))\n",
    "        return loss\n",
    "\n",
    "    def predict(self, eval_users, test_batch_size):\n",
    "        \"\"\"\n",
    "        Predict the model on test set\n",
    "        :param eval_users: evaluation (test) user\n",
    "        :param eval_pos: position of the evaluated (test) item\n",
    "        :param test_batch_size: batch size for test set\n",
    "        :return: predictions\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            input_matrix = torch.Tensor(eval_users).to(self.device)\n",
    "            preds = np.zeros_like(input_matrix.cpu())\n",
    "\n",
    "            num_data = input_matrix.shape[0]\n",
    "            num_batches = int(np.ceil(num_data / test_batch_size))\n",
    "            perm = list(range(num_data))\n",
    "            for b in range(num_batches):\n",
    "                if (b + 1) * test_batch_size >= num_data:\n",
    "                    batch_idx = perm[b * test_batch_size:]\n",
    "                else:\n",
    "                    batch_idx = perm[b * test_batch_size: (b + 1) * test_batch_size]\n",
    "                    \n",
    "                test_batch_matrix = input_matrix[batch_idx]\n",
    "                batch_pred_matrix = self.forward(test_batch_matrix)\n",
    "                batch_pred_matrix.masked_fill(test_batch_matrix.bool(), float('-inf'))\n",
    "                preds[batch_idx] = batch_pred_matrix.detach().cpu().numpy()\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8bca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config= {\n",
    "    \"data_name\": \"ml-1m\",\n",
    "    \"train_ratio\":0.8,\n",
    "  \n",
    "    \"enc_dims\": [512,128],\n",
    "    \"dropout\": 0.5,\n",
    "    \"anneal_cap\": 0.2,\n",
    "    \"total_anneal_steps\": 200000,\n",
    "  \n",
    "    \"num_epochs\": 500,\n",
    "    \"batch_size\": 512,\n",
    "    \"test_batch_size\": 512,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"early_stop\": True,\n",
    "    \"patience\": 50,\n",
    "  \n",
    "    \"top_k\": [100]\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VAE model and train in on GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"num_users is \", num_users)\n",
    "print(\"num_items is \", num_items)\n",
    "model = MultVAE(config, num_users,num_items, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573b448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trianing loop for VAE\n",
    "# at each epoch, save the model's parameters\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "total_test_losses = []\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    test_loss=0\n",
    "    total_loss = 0\n",
    "    if epoch==7:\n",
    "        optimizer.lr=0.001\n",
    "    model.train()\n",
    "    loss = model.train_one_epoch(train_array, optimizer,512)\n",
    "    train_losses.append(float(loss/num_users))\n",
    "    torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, path+f\"\\\\checkpoints\\\\VAE_epoch_{epoch}.pt\")\n",
    "    \n",
    "    \n",
    "    model.eval() \n",
    "    predictions = torch.Tensor(model.predict(test_array_without_item, num_items)).to(device)\n",
    "    ce_losses = -(F.log_softmax(predictions, 1) * torch.Tensor(test_array-test_array_without_item).to(device)).sum(1).mean()\n",
    "    total_loss += ce_losses.item()\n",
    "    total_test_losses.append(total_loss)\n",
    "    \n",
    "    print(total_test_losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(len(train_losses)), train_losses)\n",
    "plt.legend(['Train loss'])\n",
    "plt.axvline(x=np.argmin(train_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385edaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(len(total_test_losses)), total_test_losses)\n",
    "plt.legend(['Total test loss'])\n",
    "plt.axvline(x=np.argmin(total_test_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaed6ef",
   "metadata": {},
   "source": [
    "## Load best state for evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039268c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model that had the lowest test loss\n",
    "\n",
    "checkpoint = torch.load(path+f\"\\\\checkpoints\\\\VAE_epoch_{np.argmin(total_test_losses)}.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dac8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the model\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62182810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the mean test loss\n",
    "\n",
    "predictions = torch.Tensor(model.predict(test_array_without_item, 20)).to(device)\n",
    "ce_loss = -(F.log_softmax(predictions, 1) * torch.Tensor(test_array).to(device)).sum(1).mean()\n",
    "print(float(ce_loss)/test_array_without_item.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e231da",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f0a1e",
   "metadata": {},
   "source": [
    "### Metrics for evaluating VAE recommender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a340af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k(user_vector, original_user_vector, num_items, model, top_k):\n",
    "    item_prob_dict = {}\n",
    "    user_tensor = torch.Tensor(user_vector).to(device)\n",
    "    output_model = softmax(model(user_tensor)[0]).cpu().detach().numpy()\n",
    "    neg = np.ones_like(original_user_vector)- original_user_vector\n",
    "    output = neg*output_model\n",
    "    for i in range(len(output)):\n",
    "        if output[i] > 0:\n",
    "            item_prob_dict[i]=output[i]\n",
    "    sorted_items_by_prob  = sorted(item_prob_dict.items(), key=lambda item: item[1],reverse=True)\n",
    "    top_k = min(top_k, len(sorted_items_by_prob))\n",
    "    return dict(sorted_items_by_prob[:top_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aee563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_in_the_list(user_vector, original_user_vector, item_id, num_items, model):\n",
    "    top_k_list = list(get_top_k(user_vector, original_user_vector, num_items, model, num_items).keys())\n",
    "    return top_k_list.index(item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea32767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HR_at_k(users_array, y_array, model, k):\n",
    "    count=0\n",
    "    for i in range(len(users_array)):\n",
    "        user_vec = users_array[i]\n",
    "        item_id = y_array[i]\n",
    "        index = get_index_in_the_list(user_vec, user_vec, item_id, num_items, model)+1\n",
    "        if index<=k:\n",
    "            count+=1\n",
    "    return count/len(users_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE_hit_rate_and_MRR(test_array, num_items, k, model):\n",
    "    counter_10 = 0\n",
    "    counter_50 = 0\n",
    "    counter_100 = 0\n",
    "    RR = 0\n",
    "    for i in range(test_array.shape[0]):\n",
    "        item_id = test_array[i][-1]\n",
    "        user_id = test_array[i][-2]\n",
    "        item_vector = np.array(items_array[item_id])\n",
    "        user_vector = test_array[i][:-2] - item_vector\n",
    "        index = get_index_in_the_list(user_vector, user_vector, item_id, num_items, model) +1 \n",
    "        \n",
    "        if index <= 10:\n",
    "            counter_10 +=1 \n",
    "        if index <= 50:\n",
    "            counter_50 +=1 \n",
    "        if index <= 100:\n",
    "            counter_100 +=1             \n",
    "        RR+= np.reciprocal(index)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(i)\n",
    "    return counter_10/test_array.shape[0], counter_50/test_array.shape[0], counter_100/test_array.shape[0],  RR/test_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f38e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_HR_at_k(test_array_without_item,test_y_pos, model,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90618c9",
   "metadata": {},
   "source": [
    "### Check the recommendations distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274106f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recommended_item(user_tensor, recommender):\n",
    "    user_res = recommender(user_tensor)[0]\n",
    "    user_catalog = torch.ones_like(user_tensor)-user_tensor\n",
    "    user_recommenations = torch.mul(user_res, user_catalog)\n",
    "    return(torch.argmax(user_recommenations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ceeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_train = {}\n",
    "for i in range(len(train_array)):\n",
    "    vec = train_array[i]\n",
    "    tens = torch.Tensor(vec).to(device)\n",
    "    topk_train[i] = int(get_user_recommended_item(tens, model).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_test = {}\n",
    "for i in range(len(test_array)):\n",
    "    vec = test_array[i]\n",
    "    tens = torch.Tensor(vec).to(device)\n",
    "    topk_test[i] = int(get_user_recommended_item(tens, model).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cfb21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(topk_train.values(), bins=40)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf29ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(topk_test.values(), bins=40)\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
