{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07aa98da",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39225ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from scipy import sparse\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b2a6ca",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b6382-85d6-4889-bcf3-6f8efd407f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "DP_DIR = \"Data_preprocessing\"\n",
    "export_dir = Path(os.getcwd())\n",
    "files_path = Path(export_dir.parent, DP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ebeeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mixed = pd.read_csv(Path(files_path,'train_data_mixed.csv'))\n",
    "test_data = pd.read_csv(Path(files_path,'test_data.csv'))\n",
    "train_array = train_data_mixed.to_numpy()\n",
    "test_array = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98571e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(files_path,'items_values_dict_ML1.pkl'), 'rb') as f:\n",
    "    items_values_dict = pickle.load(f)\n",
    "\n",
    "with open(Path(files_path,'prob_dict.pkl'), 'rb') as f:\n",
    "    prob_dict = pickle.load(f)\n",
    "\n",
    "items_values= pd.read_csv(Path(files_path,'items_values.csv'))\n",
    "items_array = items_values.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cee2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recommended_item(user_tensor, recommender):\n",
    "    user_res = softmax(recommender(user_tensor)[0])\n",
    "    user_catalog = torch.ones_like(user_tensor)-user_tensor\n",
    "    user_recommenations = torch.mul(user_res, user_catalog)\n",
    "    return(torch.argmax(user_recommenations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1258ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get users vectors to create topk\n",
    "unique_indices = np.unique(train_array[:,-3], return_index=True, axis=0)[1]\n",
    "\n",
    "# create a new array with only the unique users\n",
    "train_unique_arr = train_array[unique_indices, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d99704",
   "metadata": {},
   "source": [
    "# VAE Model definition and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae99c58-2916-4c5a-b18a-673b396e46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb\n",
    "import importlib\n",
    "from ipynb.fs.defs.VAE import MultVAE\n",
    "importlib.reload(ipynb.fs.defs.VAE)\n",
    "from ipynb.fs.defs.VAE import MultVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6310788-9306-40fc-b20d-2ebc68f5f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "config= {\n",
    "    \"data_name\": \"ml-1m\",\n",
    "    \"train_ratio\":0.8,\n",
    "  \n",
    "    \"enc_dims\": [512,128],\n",
    "    \"dropout\": 0.5,\n",
    "    \"anneal_cap\": 0.2,\n",
    "    \"total_anneal_steps\": 200000,\n",
    "  \n",
    "    \"num_epochs\": 500,\n",
    "    \"batch_size\": 512,\n",
    "    \"test_batch_size\": 512,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"early_stop\": True,\n",
    "    \"patience\": 50,\n",
    "  \n",
    "    \"top_k\": [100]\n",
    "  }\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_users = 6040\n",
    "num_items = 3706\n",
    "print(\"num_users is \", num_users)\n",
    "print(\"num_items is \", num_items)\n",
    "VAE_recommender = MultVAE(config, num_users, num_items, device)\n",
    "optimizer = torch.optim.Adam(VAE_recommender.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda8d90",
   "metadata": {},
   "source": [
    "### load the trained VAE recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5611c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(Path(files_path,\"VAE_epoch_9.pt\"))\n",
    "VAE_recommender.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "VAE_recommender.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c05dca",
   "metadata": {},
   "source": [
    "### Recommender Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d084e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in VAE_recommender.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bdd4ff",
   "metadata": {},
   "source": [
    "### Create dictionary of the top recommended item for train and test users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca24ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_train = {}\n",
    "for i in range(len(train_array)):\n",
    "    vec = train_array[i][:-3]\n",
    "    user_id = train_array[i][-3]\n",
    "    tens = torch.Tensor(vec).to(device)\n",
    "    topk_train[user_id] = int(get_user_recommended_item(tens, VAE_recommender).cpu().detach().numpy())\n",
    "    \n",
    "topk_test = {}\n",
    "for i in range(len(test_array)):\n",
    "    vec = test_array[i][:-2]\n",
    "    user_id = test_array[i][-2]\n",
    "    tens = torch.Tensor(vec).to(device)\n",
    "    topk_test[user_id] = int(get_user_recommended_item(tens, VAE_recommender).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd07b080",
   "metadata": {},
   "source": [
    "# Backbone Model definition and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_G(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MLP_G, self).__init__()\n",
    "        self.linear_x = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.linear_y = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        user_representation = self.linear_x(user.float())\n",
    "        item_representation = self.linear_y(item.float())\n",
    "        dot_prod = torch.matmul(user_representation, item_representation.T)\n",
    "        dot_sigmoid = self.sigmoid(dot_prod)\n",
    "        \n",
    "        return dot_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender_G(nn.Module):\n",
    "    def __init__(self, num_items, hidden_size, device):\n",
    "        super(Recommender_G, self).__init__()\n",
    "        self.mlp = MLP_G(num_items, hidden_size).to(device)\n",
    "\n",
    "    def forward(self, user_vector, item_vector):\n",
    "        user_vector = user_vector.to(device)\n",
    "        item_vector = item_vector.to(device)\n",
    "        output = self.mlp(user_vector, item_vector)\n",
    "        return output.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d93d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_dim=20\n",
    "backbone = Recommender_G(num_items, hidden_dim, device)\n",
    "\n",
    "backbone.load_state_dict(torch.load(Path(files_path,\"recommender_model.pt\")))\n",
    "backbone.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc617cfe-9c04-43b1-b4dc-ba1145f5d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in backbone.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18238b55",
   "metadata": {},
   "source": [
    "# Metrics help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9da662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top k recommendations\n",
    "def get_top_k(user_vector, original_user_vector, num_items, model, top_k):\n",
    "    stime = time.time()\n",
    "    item_prob_dict = {}\n",
    "    user_tensor = torch.Tensor(user_vector).to(device)\n",
    "    output_model = [float(i) for i in softmax(model(user_tensor)[0]).cpu().detach().numpy()]\n",
    "    neg = np.ones_like(original_user_vector)- original_user_vector\n",
    "    output = neg*output_model\n",
    "    for i in range(len(output)):\n",
    "        if output[i] > 0:\n",
    "            item_prob_dict[i]=output[i]\n",
    "    sorted_items_by_prob  = sorted(item_prob_dict.items(), key=lambda item: item[1],reverse=True)\n",
    "    top_k = min(top_k, len(sorted_items_by_prob))\n",
    "    return dict(sorted_items_by_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_in_the_list(user_vector, original_user_vector, item_id, num_items, model):\n",
    "    \"\"\"\n",
    "    get the index of an item in the recommenations ranked list\n",
    "    \"\"\"\n",
    "    top_k_list = list(get_top_k(user_vector, original_user_vector, num_items, model, num_items).keys())\n",
    "    return top_k_list.index(item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ec0d0",
   "metadata": {},
   "source": [
    "#### LXR based similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221bbc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_LXR_mask(x, item_id, item_tensor, modelCombined_g):\n",
    "    \n",
    "    user_hist = x\n",
    "    user_hist[item_id] = 0\n",
    "    item_id = np.int64(item_id)\n",
    "    x_masked_g, loss1, loss2, loss3= modelCombined_g(user_hist, item_tensor, item_id, device)\n",
    "    item_sim_dict = {i: x_masked_g[i].item() for i in range(len(x_masked_g))}    \n",
    "\n",
    "    return (item_sim_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d96a683",
   "metadata": {},
   "source": [
    "#### Caclculate the POS@20 metric value for monitoring during train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51928378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pos_top_k(user_vector,  item_id, items_tensor, num_of_bins, num_items, recommender, modelCombined_g, k=20):\n",
    "\n",
    "    user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "    POS_masked = user_tensor\n",
    "    POS_masked[item_id] = 0\n",
    "    user_hist_size = np.sum(user_vector)\n",
    "\n",
    "    bins = [0] + [len(x) for x in np.array_split(np.arange(user_hist_size), num_of_bins, axis=0)]\n",
    "\n",
    "    POS_at_20 = [0] * (num_of_bins+1)\n",
    "    total_items = 0\n",
    "    \n",
    "    # returns original tensor\n",
    "    sim_items = find_LXR_mask(POS_masked, item_id, items_tensor, modelCombined_g)\n",
    "    POS_sim_items=list(sorted(sim_items.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "    for i in range(len(bins)):\n",
    "        total_items += bins[i]\n",
    "        POS_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\n",
    "        for j in POS_sim_items[:total_items]:\n",
    "            POS_masked[j[0]] = 1\n",
    "        POS_masked = user_tensor - POS_masked # remove the masked items from the user history \n",
    "        POS_index = get_index_in_the_list(POS_masked, user_vector, item_id, num_items, recommender)+1\n",
    "        POS_at_20[i] = 1 if POS_index <= 20 else 0\n",
    "        \n",
    "    res = np.array(POS_at_20)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf4af4",
   "metadata": {},
   "source": [
    "# Explainer definition & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18701830-da5e-42d3-8db9-0d96d323fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explainer_G(nn.Module):\n",
    "    def __init__(self, backbone, input_size, hidden_size, device):\n",
    "        super(Explainer_G, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        backbone_children = list(backbone.children())[0]\n",
    "\n",
    "        self.slice1 = nn.Sequential(*list(backbone_children.children())[:1])\n",
    "        self.slice2 = nn.Sequential(*list(backbone_children.children())[1:2])\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = hidden_size*2, out_features=input_size),\n",
    "            nn.Sigmoid()\n",
    "        ).to(self.device)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        slice1_output = self.slice1(user.float())\n",
    "        slice2_output = self.slice2(item.float())\n",
    "        combined_output = torch.cat((slice1_output, slice2_output), dim=-1)\n",
    "        mask = self.bottleneck(combined_output).to(self.device)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f86094-fe0c-4e09-a4e0-b5d92f0c09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossModelCombined(torch.nn.Module):\n",
    "    def __init__(self, alpha_parameter, backbone, recommender, explainer_model_g, hidden_size, device):\n",
    "        super().__init__()\n",
    "        self.alpha_parameter = alpha_parameter\n",
    "        self.recommender =  recommender\n",
    "        self.explainer_model_g = explainer_model_g\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, y_true, item_id, device):\n",
    "        \n",
    "        self.x = x.to(device) # user history tensor\n",
    "        self.y_true = torch.tensor(y_true).float().to(device) # item one hot tensor\n",
    "        \n",
    "        mask = self.explainer_model_g(self.x,self.y_true).to(device) # create mask by the explainer model\n",
    "        # \"weakened\" history: \n",
    "        x_masked = self.x * mask\n",
    "   \n",
    "        # the score of the item with the masked user vector:\n",
    "        y_masked = self.recommender(x_masked)[0]\n",
    "  \n",
    "        cross_entropy_loss = -torch.sum((F.log_softmax(y_masked, -1) * self.y_true),-1).mean()\n",
    "        #l1 loss on mask\n",
    "        \n",
    "        l1_loss = torch.mean(torch.abs(mask)).to(device)\n",
    "        \n",
    "        #combined loss\n",
    "        lossComb = cross_entropy_loss + self.alpha_parameter * l1_loss \n",
    "\n",
    "        return x_masked, cross_entropy_loss, l1_loss, lossComb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18abc2e7",
   "metadata": {},
   "source": [
    "#### Train LXR for different alphas, monitor the train process of POS@20 metric value, calculated on 100 samples test users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d58b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.00055, 0.00095, 0.00125, 0.0055]\n",
    "hidden_dim = 20\n",
    "torch.manual_seed(58)\n",
    "np.random.seed(0)\n",
    "num_of_bins = 10\n",
    "num_of_rand_users = 100\n",
    "\n",
    "random_rows = np.random.choice(test_array.shape[0], num_of_rand_users, replace=False)\n",
    "random_sampled_array = test_array[random_rows]\n",
    "lxr_epochs = 40\n",
    "batch_size = 64\n",
    "loader = torch.utils.data.DataLoader(train_unique_arr, batch_size=batch_size, shuffle=True)\n",
    "num_batches = int(np.ceil(num_users / batch_size))\n",
    "\n",
    "# dictionaries for saving the results\n",
    "train_total_losses = {}\n",
    "train_alphas = {}\n",
    "min_losses = {}\n",
    "pos_at_20_dict = {}\n",
    "min_pos_at_20 = {}\n",
    "\n",
    "\n",
    "for run in range(len(alphas)):\n",
    "    alpha_parameter = alphas[run]\n",
    "    explainer_model_g = Explainer_G(backbone, num_items, hidden_dim, device).to(device)\n",
    "    modelCombined_g = LossModelCombined(alpha_parameter, backbone, VAE_recommender, explainer_model_g, hidden_dim, device).to(device)\n",
    "    lr = 0.01\n",
    "    optimizer_comb_g = torch.optim.Adam(modelCombined_g.parameters(), lr=lr)\n",
    "    \n",
    "    run_losses = []\n",
    "    run_pos_at_20 = []\n",
    "    \n",
    "    for epoch in range(lxr_epochs):\n",
    "        if epoch==5:\n",
    "            lr = 0.005\n",
    "            optimizer_comb_g.lr = lr\n",
    "        elif epoch == 10:\n",
    "            lr = 0.001\n",
    "            optimizer_comb_g.lr = lr\n",
    "        elif epoch == 20:\n",
    "            lr = 0.0005\n",
    "            optimizer_comb_g.lr = lr\n",
    "        POS_at_20_lxr = np.zeros(num_of_bins+1)\n",
    "        print(f'epoch = {epoch} alpha = {alpha_parameter}')\n",
    "        train_loss = 0\n",
    "        total_ce_loss=0\n",
    "        total_l1_loss=0\n",
    "        modelCombined_g.train()\n",
    "        explainer_model_g.train()\n",
    "        for batch_index, samples in enumerate(loader):\n",
    "            # create data for explainer:\n",
    "            histories = samples[:,:-3]\n",
    "            user_ids = samples[:,-3]\n",
    "            top1_item = np.array([topk_train[int(x)] for x in user_ids])\n",
    "            items_vectors = items_array[top1_item]\n",
    "            items_tensors = torch.Tensor(items_vectors).to(device)\n",
    "\n",
    "            # zero grad:\n",
    "            optimizer_comb_g.zero_grad()\n",
    "            # forward:\n",
    "            batch_masks, ce_loss, l1_loss, batch_loss = modelCombined_g(histories, items_tensors, top1_item, device)\n",
    "            total_ce_loss+= ce_loss\n",
    "            total_l1_loss+= l1_loss\n",
    "            train_loss += batch_loss\n",
    "    \n",
    "            batch_loss.backward(retain_graph=True)\n",
    "            optimizer_comb_g.step()\n",
    "        run_losses.append(train_loss.cpu().detach().numpy()/train_unique_arr.shape[0])\n",
    "        print(f'Epoch {epoch}, CE loss = {total_ce_loss/train_unique_arr.shape[0]}, l1 loss = {total_l1_loss/train_unique_arr.shape[0]}')\n",
    "\n",
    "        torch.save({\n",
    "            'model_state_dict': modelCombined_g.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_comb_g.state_dict(),\n",
    "            }, f\"LXR_VAE_{alpha_parameter}_{epoch}.pt\")\n",
    "\n",
    "        torch.save({\n",
    "                'model_state_dict': explainer_model_g.state_dict()\n",
    "                }, f\"LXR_VAE_explainer_{alpha_parameter}_{epoch}.pt\")\n",
    "\n",
    "        #Monitoring on POS metric after each epoch\n",
    "        modelCombined_g.eval()\n",
    "        explainer_model_g.eval()\n",
    "        for j in range(random_sampled_array.shape[0]):\n",
    "            user_id = random_sampled_array[j][-2]\n",
    "            user_vector = random_sampled_array[j][:-2]\n",
    "\n",
    "            #get top1 of this test user item\n",
    "            top1_item_test = topk_test[user_id]\n",
    "\n",
    "            item_vector = items_array[top1_item_test]\n",
    "            items_tensor = torch.Tensor(item_vector).to(device)\n",
    "\n",
    "            user_vector[top1_item_test] = 0 \n",
    "            user_tensor = torch.Tensor(user_vector).to(device)\n",
    "\n",
    "            res = calculate_pos_top_k(user_vector, top1_item_test, items_tensor, num_of_bins, num_items, VAE_recommender, modelCombined_g, k=20)\n",
    "            POS_at_20_lxr += res\n",
    "\n",
    "        run_pos_at_20.append(np.mean(POS_at_20_lxr[1:])/random_sampled_array.shape[0])\n",
    "        print(\"POS@20 at epoch {:d} is {:.4f} \".format(int(epoch), np.mean(POS_at_20_lxr[1:])/random_sampled_array.shape[0]))\n",
    "    \n",
    "    train_total_losses[run] = run_losses # list of the loss of every epoch\n",
    "    train_alphas[run] = alpha_parameter # the alpha parameter that was used in the run\n",
    "    min_losses[run] = (np.argmin(run_losses), min(run_losses)) # the epoch which got the lowest loss and the loss \n",
    "    pos_at_20_dict[run] = run_pos_at_20 # list of the pos@20 AUC\n",
    "    min_pos_at_20[run] = (np.argmin(run_pos_at_20), min(run_pos_at_20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275627f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(pos_at_20_dict)):\n",
    "    plt.plot(pos_at_20_dict[i])\n",
    "    \n",
    "plt.legend([f'{train_alphas[i]}' for i in range(len(pos_at_20_dict))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ed972-88db-4f7c-834c-7277e4749d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
